{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import requests\n",
    "import re\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to mongo\n",
    "client = MongoClient()\n",
    "db = client['capstone']\n",
    "sid = SentimentIntensityAnalyzer()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data from mongo\n",
    "def pull_geodata(coll_name):\n",
    "    coll=db[coll_name]\n",
    "    query = coll.find({\"full_data.geo\" : {\"$exists\" : True,\"$ne\" : None}})\n",
    "    df = pd.DataFrame(list(query))\n",
    "    return df\n",
    "\n",
    "#remove emojis and urls\n",
    "def clean_text(inputString):\n",
    "    final = \"\"\n",
    "    for letter in inputString:\n",
    "        try:\n",
    "         letter.encode(\"ascii\")\n",
    "         final += letter\n",
    "        except UnicodeEncodeError:\n",
    "         final += ''\n",
    "    return re.sub(r\"http\\S+\", \"\", final)\n",
    "\n",
    "#get tweets only from US with geocoords\n",
    "#split out lat,long,text, and sentiment\n",
    "def prep_twitter_df(df):\n",
    "    df['coords'] = df['full_data'].apply(lambda x: x['geo']['coordinates'])\n",
    "    \n",
    "    code = []\n",
    "    for i in df['full_data']:\n",
    "        if i['place']:\n",
    "            code.append(i['place']['country_code'])\n",
    "        else:\n",
    "            code.append(None)\n",
    "    code = np.array(code)\n",
    "    us_df = df[code==\"US\"]\n",
    "    \n",
    "    us_df['lat'] = us_df.coords.apply(lambda x: x[0])\n",
    "    us_df['long'] = us_df.coords.apply(lambda x: x[1])\n",
    "    \n",
    "    us_df['text'] = us_df['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "    \n",
    "    \n",
    "    us_df['sentiment'] = us_df['text'].apply(lambda x: sid.polarity_scores(x))\n",
    "    #us_df['sentiment'] = us_df['sentiment'].apply(ast.literal_eval)\n",
    "    return us_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join census data\n",
    "def get_census(coords):\n",
    "    url='https://geo.fcc.gov/api/census/area?lat={}&lon={}&format=json'.format(coords[0],coords[1])\n",
    "    res = requests.get(url)\n",
    "    if res.json()['results']==[]:\n",
    "        return None\n",
    "    else:\n",
    "        return res.json()['results'][0]['block_fips'][:-4]\n",
    "\n",
    "#call fcc api to convert lat,long pairs to census tracts in US\n",
    "def census_df(df):\n",
    "    census = []\n",
    "    count=0\n",
    "    req_count=0\n",
    "    while len(census)< df.shape[0]:\n",
    "        census.append(get_census(df['coords'].iloc[count]))\n",
    "        req_count+=1\n",
    "        count+=1\n",
    "        if req_count % 1000 == 0:\n",
    "            print(\"Current count: \",req_count)\n",
    "            time.sleep(30)\n",
    "\n",
    "    df['census']=census\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper function to do the above\n",
    "def pull_to_csv(coll_name,path_for_csv):\n",
    "    df1 = pull_geodata(coll_name)\n",
    "    us_df = prep_twitter_df(df1)\n",
    "    census_update = census_df(us_df)\n",
    "    census_update.to_csv(path_for_csv)\n",
    "    return census_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEALTHY FOODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df = pull_geodata('healthy')\n",
    "\n",
    "us_healthy = prep_twitter_df(healthy_df)\n",
    "\n",
    "census_healthy = census_df(us_healthy)\n",
    "\n",
    "census_healthy.to_csv(\"data/twitter_mongo/census_healthy1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_healthy = pull_to_csv('healthy',\"data/twitter_mongo/census_healthy1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEALTHY FOODS Second Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_df2 = pull_geodata('healthy2')\n",
    "\n",
    "us_healthy2 = prep_twitter_df(healthy_df2)\n",
    "\n",
    "census_healthy2 = census_df(us_healthy2)\n",
    "\n",
    "census_healthy2.to_csv(\"data/census_healthy2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_healthy2 = pull_to_csv('healthy2',\"data/twitter_mongo/census_healthy2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNHEALTHY FOODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhealthy_df = pull_geodata('unhealthy')\n",
    "\n",
    "us_unhealthy = prep_twitter_df(unhealthy_df)\n",
    "\n",
    "census_unhealthy = census_df(us_unhealthy)\n",
    "\n",
    "census_unhealthy.to_csv(\"data/census_unhealthy1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_unhealthy = pull_to_csv('unhealthy',\"data/twitter_mongo/census_unhealthy1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEALTHY FOODS Second Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhealthy_df2 = pull_geodata('unhealthy2')\n",
    "\n",
    "us_unhealthy2 = prep_twitter_df(unhealthy_df2)\n",
    "\n",
    "census_unhealthy2 = census_df(us_unhealthy2)\n",
    "\n",
    "census_unhealthy2.to_csv(\"data/census_unhealthy2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_unhealthy2 = pull_to_csv('unhealthy2',\"data/twitter_mongo/census_unhealthy2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROCERY STORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_df = pull_geodata('grocery_stores')\n",
    "\n",
    "us_grocery = prep_twitter_df(grocery_df)\n",
    "\n",
    "census_grocery = census_df(us_grocery)\n",
    "\n",
    "census_grocery.to_csv(\"data/census_grocery1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_grocery = pull_to_csv('grocery_stores',\"data/twitter_mongo/census_healthy2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grocery Second Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_df2 = pull_geodata('grocery_stores2')\n",
    "\n",
    "us_grocery2 = prep_twitter_df(grocery_df2)\n",
    "\n",
    "census_grocery2 = census_df(us_grocery2)\n",
    "\n",
    "census_grocery2.to_csv(\"data/census_grocery2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_grocery2 = pull_to_csv('grocery_stores2',\"data/twitter_mongo/census_grocery2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAST FOOD STORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastfood_df = pull_geodata('ff_stores')\n",
    "\n",
    "us_fastfood = prep_twitter_df(fastfood_df)\n",
    "\n",
    "census_fastfood = census_df(us_fastfood)\n",
    "\n",
    "census_fastfood.to_csv(\"data/twitter_mongo/census_fastfood1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_fast_food = pull_to_csv('ff_stores',\"data/twitter_mongo/census_fastfood1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAST FOODS Second Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastfood_df2 = pull_geodata('ff_stores2')\n",
    "\n",
    "us_fastfood2 = prep_twitter_df(fastfood_df2)\n",
    "\n",
    "census_fastfood2 = census_df(us_fastfood2)\n",
    "\n",
    "census_fastfood2.to_csv(\"data/twitter_mongo/census_fastfood2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_fastfood2 = pull_to_csv('ff_stores2',\"data/twitter_mongo/census_fastfood2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
