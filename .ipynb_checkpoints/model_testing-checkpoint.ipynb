{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning_script import prep_data\n",
    "from model1 import my_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score,recall_score,precision_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#call clean_data on each train and test X inside prep data to split and get data ready for modeling\n",
    "df_train,y_train,df_test,y_test= prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 1\n",
      "\n",
      "TRAIN\n",
      "ROC_AUC Logistic:  0.8664619834948086\n",
      "Accuracy Logistic:  0.7860669226549644\n",
      "f1 Logistic:  0.6834526480336256\n",
      "\n",
      "TEST\n",
      "ROC_AUC Logistic:  0.7528683028793485\n",
      "Accuracy Logistic:  0.7849665924276169\n",
      "f1 Logistic:  0.6811953112101701\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression 1\")\n",
    "print()\n",
    "model_log = LogisticRegression(penalty='l1')\n",
    "\n",
    "print(\"TRAIN\")\n",
    "print(\"ROC_AUC Logistic: \", cross_val_score(LogisticRegression(),df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy Logistic: \", cross_val_score(LogisticRegression(),df_train,y_train,cv=5).mean())\n",
    "print(\"f1 Logistic: \", cross_val_score(LogisticRegression(),df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "model_log.fit(df_train,y_train)\n",
    "y_pred = model_log.predict(df_test)\n",
    "print()\n",
    "print(\"TEST\")\n",
    "print(\"ROC_AUC Logistic: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy Logistic: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 Logistic: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST 1\n",
      "\n",
      "TRAIN on RF\n",
      "ROC_AUC score:  0.8892857562442726\n",
      "Accuracy score:  0.8144267690619857\n",
      "f1 score:  0.7369319111050956\n",
      "\n",
      "TEST on RF\n",
      "ROC_AUC score:  0.7880613446261119\n",
      "Accuracy score:  0.8130289532293986\n",
      "f1 score:  0.7290624495723738\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM FOREST 1\")\n",
    "print()\n",
    "#fit RF model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#train stats\n",
    "print(\"TRAIN on RF\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "#call pred and print test stats\n",
    "model.fit(df_train,y_train)\n",
    "y_pred = model.predict(df_test)\n",
    "print()\n",
    "print(\"TEST on RF\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for RF\n",
    "param_grid={'n_estimators': [300,400,500],\n",
    "            'max_depth': [3, None,1,2,5],\n",
    "            'max_features': ['sqrt','log2', None]\n",
    "           }\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid=param_grid,n_jobs=-1,scoring=\"f1\",cv=5)\n",
    "grid.fit(df_train,y_train)\n",
    "\n",
    "best_estimator = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST 2 (GS)\n",
      "\n",
      "TRAIN on RF_GS\n",
      "ROC_AUC score:  0.912223651610444\n",
      "Accuracy score:  0.8375205704882063\n",
      "f1 score:  0.7809174448833118\n",
      "\n",
      "TEST on RF_GS\n",
      "ROC_AUC score:  0.831062633925188\n",
      "Accuracy score:  0.8388641425389755\n",
      "f1 score:  0.7820454887784304\n"
     ]
    }
   ],
   "source": [
    "#new RF model after GS\n",
    "best_rf_model = grid.best_estimator_\n",
    "\n",
    "#new RF params\n",
    "print(\"RANDOM FOREST 2 (GS)\")\n",
    "print()\n",
    "\n",
    "#train stats\n",
    "print(\"TRAIN on RF_GS\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(best_rf_model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(best_rf_model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(best_rf_model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "#predict and get test stats\n",
    "best_rf_model.fit(df_train,y_train)\n",
    "y_pred = best_rf_model.predict(df_test)\n",
    "\n",
    "print()\n",
    "print(\"TEST on RF_GS\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN on DT\n",
      "ROC_AUC score:  0.8764307588680811\n",
      "Accuracy score:  0.8088315962698847\n",
      "f1 score:  0.7396114980886782\n",
      "TEST on DT\n",
      "ROC_AUC score:  0.7893913380116717\n",
      "Accuracy score:  0.8062360801781737\n",
      "f1 score:  0.730399752091726\n"
     ]
    }
   ],
   "source": [
    "#Decision tree trial 1\n",
    "print(\"DECISION TREE 1\")\n",
    "print()\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=13, min_samples_split=2)\n",
    "\n",
    "#train stats\n",
    "print(\"TRAIN on DT\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "#predict and get test stats\n",
    "model.fit(df_train,y_train)\n",
    "y_pred = model.predict(df_test)\n",
    "\n",
    "print()\n",
    "print(\"TEST on DT\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBtrial 1\n",
    "print(\"GRADIENT BOOSTING 1\")\n",
    "print()\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "print(\"TRAIN on GB_GS\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "model.fit(df_train,y_train)\n",
    "y_pred = model.predict(df_test)\n",
    "print()\n",
    "print(\"TEST\")\n",
    "print(\"ROC_AUC DT: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy DT: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 DT: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1500 candidates, totalling 4500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 37.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4500 out of 4500 | elapsed: 42.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'max_depth': 6, 'max_features': 5, 'min_samples_leaf': 7, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#gradient boosting grid search\n",
    "gb_grid = {'n_estimators': [10,50,100],\n",
    "                  'min_samples_leaf': [1, 7, 9, 13],\n",
    "                  'max_depth': [3, 4, 5, 6, 7],\n",
    "                  'max_features': [2, 5, 10, 12,15],\n",
    "                  'learning_rate': [0.05, 0.02, 0.01,.1,1]}\n",
    "gb_gridsearch = GridSearchCV(GradientBoostingClassifier(),\n",
    "                             gb_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "gb_gridsearch.fit(df_train, y_train)\n",
    "\n",
    "print( \"best parameters:\", gb_gridsearch.best_params_ )\n",
    "\n",
    "best_gb_model = gb_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=7, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb_model.fit(df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN on GB_GS\n",
      "ROC_AUC score:  0.9102661729729448\n",
      "Accuracy score:  0.8352715304443226\n",
      "f1 score:  0.7773797054652114\n",
      "TEST on GB_GS\n",
      "ROC_AUC score:  0.8233274854103364\n",
      "Accuracy score:  0.8332962138084633\n",
      "f1 score:  0.7728031567764456\n"
     ]
    }
   ],
   "source": [
    "#GBtrial 2 GS\n",
    "#Best so far\n",
    "print(\"GRADIENT BOOSTING 2 GS\")\n",
    "print()\n",
    "\n",
    "print(\"TRAIN on GB_GS\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(best_gb_model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(best_gb_model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(best_gb_model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "best_gb_model.fit(df_train,y_train)\n",
    "y_pred = best_gb_model.predict(df_test)\n",
    "\n",
    "print()\n",
    "print(\"TEST on GB_GS\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))\n",
    "print(\"recall score: \", recall_score(y_test,y_pred))\n",
    "print(\"precision score: \", precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
