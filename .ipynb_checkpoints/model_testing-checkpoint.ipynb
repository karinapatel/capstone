{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaning_script import prep_data\n",
    "from model1 import my_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score,recall_score,precision_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.cbook' has no attribute '_define_aliases'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-0eb9517d917f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pylab.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    243\u001b[0m     window_hanning, window_none)\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontour\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from . import (_path, artist, cbook, cm, colors as mcolors, docstring,\n\u001b[0m\u001b[1;32m     20\u001b[0m                lines as mlines, path as mpath, transforms)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m @cbook._define_aliases({\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;34m\"antialiased\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"aa\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;34m\"color\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.cbook' has no attribute '_define_aliases'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#call clean_data on each train and test X inside prep data to split and get data ready for modeling\n",
    "df_train,y_train,df_test,y_test= prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 1\n",
      "\n",
      "TRAIN\n",
      "ROC_AUC Logistic:  0.8664619834948086\n",
      "Accuracy Logistic:  0.7860669226549644\n",
      "f1 Logistic:  0.6834526480336256\n",
      "\n",
      "TEST\n",
      "ROC_AUC Logistic:  0.7528683028793485\n",
      "Accuracy Logistic:  0.7849665924276169\n",
      "f1 Logistic:  0.6811953112101701\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression 1\")\n",
    "print()\n",
    "model_log = LogisticRegression(penalty='l1')\n",
    "\n",
    "print(\"TRAIN\")\n",
    "print(\"ROC_AUC Logistic: \", cross_val_score(LogisticRegression(),df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy Logistic: \", cross_val_score(LogisticRegression(),df_train,y_train,cv=5).mean())\n",
    "print(\"f1 Logistic: \", cross_val_score(LogisticRegression(),df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "model_log.fit(df_train,y_train)\n",
    "y_pred = model_log.predict(df_test)\n",
    "print()\n",
    "print(\"TEST\")\n",
    "print(\"ROC_AUC Logistic: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy Logistic: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 Logistic: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST 1\n",
      "\n",
      "TRAIN on RF\n",
      "ROC_AUC score:  0.8892857562442726\n",
      "Accuracy score:  0.8144267690619857\n",
      "f1 score:  0.7369319111050956\n",
      "\n",
      "TEST on RF\n",
      "ROC_AUC score:  0.7880613446261119\n",
      "Accuracy score:  0.8130289532293986\n",
      "f1 score:  0.7290624495723738\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM FOREST 1\")\n",
    "print()\n",
    "#fit RF model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "#train stats\n",
    "print(\"TRAIN on RF\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "#call pred and print test stats\n",
    "model.fit(df_train,y_train)\n",
    "y_pred = model.predict(df_test)\n",
    "print()\n",
    "print(\"TEST on RF\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for RF\n",
    "param_grid={'n_estimators': [300,400,500],\n",
    "            'max_depth': [3, None,1,2,5],\n",
    "            'max_features': ['sqrt','log2', None]\n",
    "           }\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(),param_grid=param_grid,n_jobs=-1,scoring=\"f1\",cv=5)\n",
    "grid.fit(df_train,y_train)\n",
    "\n",
    "best_estimator = grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST 2 (GS)\n",
      "\n",
      "TRAIN on RF_GS\n",
      "ROC_AUC score:  0.912223651610444\n",
      "Accuracy score:  0.8375205704882063\n",
      "f1 score:  0.7809174448833118\n",
      "\n",
      "TEST on RF_GS\n",
      "ROC_AUC score:  0.831062633925188\n",
      "Accuracy score:  0.8388641425389755\n",
      "f1 score:  0.7820454887784304\n"
     ]
    }
   ],
   "source": [
    "#new RF model after GS\n",
    "best_rf_model = grid.best_estimator_\n",
    "\n",
    "#new RF params\n",
    "print(\"RANDOM FOREST 2 (GS)\")\n",
    "print()\n",
    "\n",
    "#train stats\n",
    "print(\"TRAIN on RF_GS\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(best_rf_model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(best_rf_model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(best_rf_model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "#predict and get test stats\n",
    "best_rf_model.fit(df_train,y_train)\n",
    "y_pred = best_rf_model.predict(df_test)\n",
    "\n",
    "print()\n",
    "print(\"TEST on RF_GS\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN on DT\n",
      "ROC_AUC score:  0.8764307588680811\n",
      "Accuracy score:  0.8088315962698847\n",
      "f1 score:  0.7396114980886782\n",
      "TEST on DT\n",
      "ROC_AUC score:  0.7893913380116717\n",
      "Accuracy score:  0.8062360801781737\n",
      "f1 score:  0.730399752091726\n"
     ]
    }
   ],
   "source": [
    "#Decision tree trial 1\n",
    "print(\"DECISION TREE 1\")\n",
    "print()\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_leaf=13, min_samples_split=2)\n",
    "\n",
    "#train stats\n",
    "print(\"TRAIN on DT\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "#predict and get test stats\n",
    "model.fit(df_train,y_train)\n",
    "y_pred = model.predict(df_test)\n",
    "\n",
    "print()\n",
    "print(\"TEST on DT\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBtrial 1\n",
    "print(\"GRADIENT BOOSTING 1\")\n",
    "print()\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "print(\"TRAIN on GB_GS\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "model.fit(df_train,y_train)\n",
    "y_pred = model.predict(df_test)\n",
    "print()\n",
    "print(\"TEST\")\n",
    "print(\"ROC_AUC DT: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy DT: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 DT: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1500 candidates, totalling 4500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 37.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4500 out of 4500 | elapsed: 42.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'learning_rate': 0.1, 'max_depth': 6, 'max_features': 5, 'min_samples_leaf': 7, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#gradient boosting grid search\n",
    "gb_grid = {'n_estimators': [10,50,100],\n",
    "                  'min_samples_leaf': [1, 7, 9, 13],\n",
    "                  'max_depth': [3, 4, 5, 6, 7],\n",
    "                  'max_features': [2, 5, 10, 12,15],\n",
    "                  'learning_rate': [0.05, 0.02, 0.01,.1,1]}\n",
    "gb_gridsearch = GridSearchCV(GradientBoostingClassifier(),\n",
    "                             gb_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "gb_gridsearch.fit(df_train, y_train)\n",
    "\n",
    "print( \"best parameters:\", gb_gridsearch.best_params_ )\n",
    "\n",
    "best_gb_model = gb_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=5, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=7, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gb_model.fit(df_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN on GB_GS\n",
      "ROC_AUC score:  0.9102661729729448\n",
      "Accuracy score:  0.8352715304443226\n",
      "f1 score:  0.7773797054652114\n",
      "TEST on GB_GS\n",
      "ROC_AUC score:  0.8233274854103364\n",
      "Accuracy score:  0.8332962138084633\n",
      "f1 score:  0.7728031567764456\n"
     ]
    }
   ],
   "source": [
    "#GBtrial 2 GS\n",
    "#Best so far\n",
    "print(\"GRADIENT BOOSTING 2 GS\")\n",
    "print()\n",
    "\n",
    "print(\"TRAIN on GB_GS\")\n",
    "print(\"ROC_AUC score: \", cross_val_score(best_gb_model,df_train,y_train,cv=5,scoring='roc_auc').mean())\n",
    "print(\"Accuracy score: \", cross_val_score(best_gb_model,df_train,y_train,cv=5).mean())\n",
    "print(\"f1 score: \", cross_val_score(best_gb_model,df_train,y_train,cv=5,scoring='f1').mean())\n",
    "\n",
    "best_gb_model.fit(df_train,y_train)\n",
    "y_pred = best_gb_model.predict(df_test)\n",
    "\n",
    "print()\n",
    "print(\"TEST on GB_GS\")\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_test,y_pred))\n",
    "print(\"Accuracy score: \", accuracy_score(y_test,y_pred))\n",
    "print(\"f1 score: \", f1_score(y_test,y_pred))\n",
    "print(\"recall score: \", recall_score(y_test,y_pred))\n",
    "print(\"precision score: \", precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance(model, X_test, y_test, scorer=f1_score):\n",
    "    ''' Calculates permutation feature importance for a fitted model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: anything with a predict() method\n",
    "    X_test, y_test: numpy arrays of data\n",
    "        unseen by model\n",
    "    scorer: function. Should be a \"higher is better\" scoring function,\n",
    "        meaning that if you want to use an error metric, you should\n",
    "        multiply it by -1 first.\n",
    "        ex: >> neg_mse = lambda y1, y2: -mean_squared_error(y1, y2)\n",
    "            >> permutation_importance(mod, X, y, scorer=neg_mse)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    feat_importances: numpy array of permutation importance\n",
    "        for each feature\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    feat_importances = np.zeros(X_test.shape[1])\n",
    "    test_score = scorer(model.predict(X_test), y_test)\n",
    "    for i in range(X_test.shape[1]):\n",
    "        X_test_shuffled = shuffle_column(X_test, i)\n",
    "        test_score_permuted = scorer(y_test, model.predict(X_test_shuffled))\n",
    "        feat_importances[i] = test_score - test_score_permuted\n",
    "    return feat_importances\n",
    "\n",
    "def shuffle_column(X, feature_index):\n",
    "    ''' \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: numpy array\n",
    "    feature_index: int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_new: numpy array\n",
    "    \n",
    "    Returns a new array identical to X but\n",
    "    with all the values in column feature_index\n",
    "    shuffled\n",
    "    '''   \n",
    "    \n",
    "    X_new = X.copy()\n",
    "    np.random.shuffle(X_new[:,feature_index])\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot of feature importances\n",
    "def plot_feat_import(f_imps, names, n):\n",
    "    sorts = np.argsort(f_imps)\n",
    "    \n",
    "    last_x = f_imps[sorts[-n:]]\n",
    "    last_x_names = names[sorts[-n:]]\n",
    "\n",
    "    idx = np.arange(len(names))\n",
    "\n",
    "    plt.barh(idx[-n:], last_x, align='center')\n",
    "    plt.yticks(idx[-n:], last_x_names)\n",
    "\n",
    "    plt.title(\"Permutation Importances in Random Forrest\")\n",
    "    plt.xlabel('Relative Importance of Feature')\n",
    "    plt.ylabel('Feature Name')\n",
    "    plt.savefig(\"feature_importances.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a366f3ddfdb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpermutation_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_gb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_feat_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-c4de059e0f43>\u001b[0m in \u001b[0;36mplot_feat_import\u001b[0;34m(f_imps, names, n)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_x_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "f_imp = permutation_importance(best_gb_model,df_test.values,y_test.values)\n",
    "plot_feat_import(f_imp, df_test.columns, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
