{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import requests\n",
    "import re\n",
    "import unicodedata\n",
    "from unidecode import unidecode\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('../data/target.csv',index_col=0)\n",
    "target['CensusTract'] = target['CensusTract'].apply(lambda x: \"0\"+str(x) if len(str(x))==10 else str(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>LILATracts_1And10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001020100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001020200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001020300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01001020400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01001020500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CensusTract  LILATracts_1And10\n",
       "0  01001020100                  0\n",
       "1  01001020200                  0\n",
       "2  01001020300                  0\n",
       "3  01001020400                  0\n",
       "4  01001020500                  0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to mongo\n",
    "client = MongoClient()\n",
    "db = client['capstone']\n",
    "sid = SentimentIntensityAnalyzer()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join census data\n",
    "def get_census(coords):\n",
    "    url='https://geo.fcc.gov/api/census/area?lat={}&lon={}&format=json'.format(coords[0],coords[1])\n",
    "    res = requests.get(url)\n",
    "    if res.json()['results']==[]:\n",
    "        return None\n",
    "    else:\n",
    "        return res.json()['results'][0]['block_fips'][:-4]\n",
    "\n",
    "#call fcc api to convert lat,long pairs to census tracts in US\n",
    "def census_df(df):\n",
    "    census = []\n",
    "    count=0\n",
    "    req_count=0\n",
    "    while len(census)< df.shape[0]:\n",
    "        census.append(get_census(df['coords'].iloc[count]))\n",
    "        req_count+=1\n",
    "        count+=1\n",
    "        if req_count % 1000 == 0:\n",
    "            print(\"Current count: \",req_count)\n",
    "            time.sleep(30)\n",
    "\n",
    "    df['census']=census\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data from mongo\n",
    "def pull_geodata(coll_name):\n",
    "    coll=db[coll_name]\n",
    "    query = coll.find({\"full_data.geo\" : {\"$exists\" : True,\"$ne\" : None}})\n",
    "    df = pd.DataFrame(list(query))\n",
    "    return df\n",
    "\n",
    "#remove emojis and urls\n",
    "def clean_text(inputString):\n",
    "    final = \"\"\n",
    "    for letter in inputString:\n",
    "        try:\n",
    "            letter.encode(\"ascii\")\n",
    "            final += letter\n",
    "        except UnicodeEncodeError:\n",
    "            final += ''\n",
    "    return re.sub(r\"http\\S+\", \"\", final)\n",
    "\n",
    "#get tweets only from US with geocoords\n",
    "#split out lat,long,text, and sentiment\n",
    "def prep_twitter_df(df,category):\n",
    "    \n",
    "    target = pd.read_csv('../data/target.csv')\n",
    "    target['CensusTract'] = target['CensusTract'].apply(lambda x: \"0\"+str(x) if len(str(x))==10 else str(x)) \n",
    "    \n",
    "    df['coords'] = df['full_data'].apply(lambda x: x['geo']['coordinates'])\n",
    "    \n",
    "    code = []\n",
    "    for i in df['full_data']:\n",
    "        if i['place']:\n",
    "            code.append(i['place']['country_code'])\n",
    "        else:\n",
    "            code.append(None)\n",
    "    code = np.array(code)\n",
    "    us_df = df[code==\"US\"]\n",
    "\n",
    "    us_df['lat'] = us_df.coords.apply(lambda x: x[0])\n",
    "    us_df['long'] = us_df.coords.apply(lambda x: x[1])\n",
    "    \n",
    "    us_df['text'] = us_df['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "    \n",
    "    us_df['sentiment'] = us_df['text'].apply(lambda x: sid.polarity_scores(x))\n",
    "    \n",
    "    if type(us_df['sentiment'][0]) == str:\n",
    "        us_df['sentiment'] = us_df['sentiment'].apply(ast.literal_eval)\n",
    "\n",
    "    us_df = us_df[(us_df['long']>-161)&(us_df['long']<-68)&(us_df['lat']>20)&(us_df['lat']<64)]\n",
    "    \n",
    "    us_df = census_df(us_df)\n",
    "\n",
    "    us_df['census'] = us_df['census'].apply(lambda x: \"0\"+str(x) if len(str(x))==10 else str(x)) \n",
    "\n",
    "    us_df.census=us_df.census.apply(float)\n",
    "\n",
    "    us_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "    us_df.census= us_df.census.apply(int)\n",
    "\n",
    "    us_df['census']=us_df['census'].apply(lambda x: \"0\"+str(x) if len(str(x))==10 else str(x)) \n",
    "\n",
    "    us_df['comp']=us_df['sentiment'].apply(lambda x: x['compound'])\n",
    "\n",
    "    us_df['category']=category\n",
    "\n",
    "    us_df = pd.merge(us_df,target,how='inner',left_on=\"census\",right_on=\"CensusTract\")\n",
    "\n",
    "    us_df['county'] = us_df['census'].apply(lambda x: x[:5])\n",
    "    \n",
    "    us_df = us_df[['keyword','text','lat','long','census','comp','category','LILATracts_1And10','county']]\n",
    "    \n",
    "    return us_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper function to do the above\n",
    "def pull_to_csv(coll_name,path_for_csv,category):\n",
    "    df1 = pull_geodata(coll_name)\n",
    "    us_df = prep_twitter_df(df1,category)\n",
    "    us_df.to_csv(path_for_csv)\n",
    "    return us_df\n",
    "\n",
    "#takes in collection and path to pull the cleaned data from and insert to mongo\n",
    "def clean_to_mongo(coll_name, path_to_csv):\n",
    "    coll=db[coll_name]\n",
    "    \n",
    "    df = pd.read_csv(path_to_csv, index_col=0)\n",
    "    data = df.to_dict(orient='records')\n",
    "    coll.insert_many(data)\n",
    "    \n",
    "#saves the csv data from mongo as a df \n",
    "def mongo_to_csv(coll_name,csv_path):\n",
    "    coll=db[coll_name]\n",
    "    query = coll.find()\n",
    "    df = pd.DataFrame(list(query))\n",
    "    df.to_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEALTHY FOODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy = pull_to_csv('healthy_clean',\"../data/twitter_mongo/healthy_final.csv\",\"healthy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNHEALTHY FOODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhealthy = pull_to_csv('unhealthy_clean',\"../data/twitter_mongo/unhealthy_final.csv\",\"unhealthy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GROCERY STORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery = pull_to_csv('grocery_stores_clean',\"../data/twitter_mongo/grocery_stores_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAST FOOD STORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_food = pull_to_csv('ff_stores_clean',\"../data/twitter_mongo/ff_stores_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Healthy cleaned data to mongo\n",
    "EX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll=db['healthy_clean']\n",
    "\n",
    "clean_to_mongo('healthy_clean',\"../data/census_healthy2.csv\")\n",
    "\n",
    "coll.count()\n",
    "\n",
    "#combined csv with all data from mongo\n",
    "mongo_to_csv('healthy_clean',\"../data/healthy_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
